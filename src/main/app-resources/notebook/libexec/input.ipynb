{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-ext-02-03-03 - NDVI long term averages of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI long term averages of growing season time series per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'NDVI long term averages of growing season time series per pixel'),\n",
    "                ('abstract', 'NDVI long term averages of growing season time series per pixel'),\n",
    "                ('id', 'ewf-ext-02-03-03')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON ((-8.864205 38.88616500000001, -8.864205 38.986165, -8.964205000000002 38.986165, -8.964205000000002 38.88616500000001, -8.864205 38.88616500000001))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'P001'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggIndex = dict([('id', 'aggIndex'),\n",
    "                 ('value', 'better-ext-02-03-02'),\n",
    "                 ('title', 'NDVI growing season statistics catalog index'),\n",
    "                 ('abstract', 'index to access ndvi catalog'),\n",
    "                 ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggApikey = dict([('id', 'aggApikey'),\n",
    "                  ('value', ''),\n",
    "                  ('title', 'NDVI growing season statistics catalog apikey'),\n",
    "                  ('abstract', 'apikey to access ndvi catalog'),\n",
    "                  ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the NDVI stats' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2015, 2015\n",
    "#difNdvi\n",
    "#input_identifiers = ('LE07_difNdvi_P001_2015005_2015020.tif', 'LE07_difNdvi_P001_2016005_2016020.tif', 'LE07_difNdvi_P001_2017005_2017020.tif')\n",
    "\n",
    "#input_identifiers = ['A9A9B699C940F7BA2E06C5B76757A7294EF2E133', 'B42DB3B71A12441EEC08E3FBBE34122FFBFCECD2', 'F6B74E8ABE6A8E3464E00BC6332ABEF26931BBBF']\n",
    "\n",
    "input_identifiers = ['2A31BAABB14E151230697AD226D3DACB73C46B55', '94096912DA71E1FE48D825F9660C08FA71D72CEC', 'D27DA2CB5E74A38B60DB44524E53404ABD2BF2CC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#input_references = tuple(['https://catalog.terradue.com/modis/search?format=atom&uid={0}'.format(pid) for pid in input_identifiers])\n",
    "\n",
    "#input_references = ['https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=A9A9B699C940F7BA2E06C5B76757A7294EF2E133', 'https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=B42DB3B71A12441EEC08E3FBBE34122FFBFCECD2', 'https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=F6B74E8ABE6A8E3464E00BC6332ABEF26931BBBF']\n",
    "\n",
    "input_references = ['https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=2A31BAABB14E151230697AD226D3DACB73C46B55', 'https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=94096912DA71E1FE48D825F9660C08FA71D72CEC', 'https://catalog.terradue.com/better-ext-02-03-02/search?format=atom&uid=D27DA2CB5E74A38B60DB44524E53404ABD2BF2CC']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/dev/ewf-ext-02-03-02/src/main/app-resources/notebook/libexec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,startdate,enddate,wkt,title',creds='{}:{}'.format(aggIndex['value'],aggApikey['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "    \n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, output_projection=None, output_geotransform=None, mask=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "        \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "    output.FlushCache()\n",
    "    \n",
    "    \n",
    "    \n",
    "def matrix_sum(mat1, mat2, no_data_value=None):\n",
    "    \n",
    "    if no_data_value is not None:\n",
    "        \n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = -9999.0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = -9999.0\n",
    "            \n",
    "            \n",
    "    msum = mat1 + mat2\n",
    "        \n",
    "    msum[(mat1 == -9999.0)] = -9999.0\n",
    "    msum[(mat2 == -9999.0)] = -9999.0\n",
    "        \n",
    "    return msum\n",
    "    \n",
    "    \n",
    "    \n",
    "def calc_average(matrix_list, n_years):\n",
    "    \n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    result = matrix_list[0]\n",
    "    \n",
    "    for i in range(1, n_years):\n",
    "        result = matrix_sum(result, matrix_list[i])\n",
    "    \n",
    "    return np.divide(result, (n_years*1.00), out=np.zeros(result.shape) - 9999.0, where=result > -9998)\n",
    "\n",
    "\n",
    "#\n",
    "# calcs avg of matrix_list\n",
    "# it takes into account pixels with no_data_values in the time series \n",
    "# it has option for circular mean\n",
    "#\n",
    "def calc_average_circular_mean (snow_matrix_list, no_data_value, apply_circular_mean = False):\n",
    "\n",
    "    mean_mat = np.ones(snow_matrix_list[0].shape) * no_data_value\n",
    "\n",
    "    for i in range(snow_matrix_list[0].shape[0]):\n",
    "        for j in range(snow_matrix_list[0].shape[1]):       \n",
    "            vals = []\n",
    "            for k in range(len(snow_matrix_list)):\n",
    "                v = snow_matrix_list[k][i,j]\n",
    "                if (v != no_data_value):\n",
    "                    vals.append(v)\n",
    "        \n",
    "            if len(vals) > 0:\n",
    "                #print(np.mean(vals))\n",
    "            \n",
    "                if (apply_circular_mean):\n",
    "                    mean_mat[i,j] = stats.circmean(vals, high=365, low=1)\n",
    "                else:\n",
    "                    mean_mat[i,j] = np.mean(vals)\n",
    "                    \n",
    "    return mean_mat\n",
    "\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "\n",
    "def calc_lta(file_list, apply_circular_mean = False):\n",
    "    \n",
    "    if file_list:\n",
    "        \n",
    "        n_years = len(file_list)\n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        print('Aggregations converted to matrices')\n",
    "        \n",
    "        \n",
    "        if apply_circular_mean:\n",
    "            lta = calc_average_circular_mean (agr_period_matrix, -9999, apply_circular_mean)\n",
    "        else:\n",
    "            lta = calc_average(agr_period_matrix, n_years)\n",
    "        \n",
    "        \n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        \n",
    "        #for file_ in file_list:\n",
    "        #    os.remove(file_)\n",
    "        \n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def write_output(temp_folder, lta, period_start_date, period_end_date, mission_name, product_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    \n",
    "    start_day_year = \"{:03d}\".format(period_start_date.timetuple().tm_yday)\n",
    "    end_day_year = \"{:03d}\".format(period_end_date.timetuple().tm_yday)\n",
    "       \n",
    "    #path_name_ini = os.path.join(temp_folder, 'LTA_' )\n",
    "    #output_name = temp_folder + '/' + 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + start_day_month + '_' + end_day_month + '_' + str(period_start_date.year) + '_' + str(period_end_date.year) + '.tif'\n",
    "    \n",
    "    #output_name = os.path.join(temp_folder, 'LTA_' + product_type + '_' + region +  '_' + start_day_month + '_' + end_day_month + '_' + str(period_start_date.year) + '_' + str(period_end_date.year) + '.tif')\n",
    "    \n",
    "    output_name = os.path.join(temp_folder, '_'.join(['LTA', mission_name, product_type, region, start_day_year + '-' + end_day_year, str(period_start_date.year) + '-' + str(period_end_date.year)]) + '.tif' )\n",
    "    \n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    \n",
    "    return output_name\n",
    "\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = datetime.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load metadata from catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Loading metadata from catalog' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "input_metadata = get_input_metadata (input_references)\n",
    "\n",
    "# order by startdate\n",
    "input_metadata = input_metadata.sort_values(by='startdate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compute Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_list = [os.path.join(data_path, in_id.split('/')[-1]) for in_id in input_identifiers]\n",
    "file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metadata['enclosure']]\n",
    "\n",
    "# first image\n",
    "startdate = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')[-2]\n",
    "enddate = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')[-1]\n",
    "\n",
    "startdate_firstproduct = datetime.datetime.strptime(startdate, \"%Y%j\")\n",
    "enddate_firstproduct = datetime.datetime.strptime(enddate, \"%Y%j\")\n",
    "\n",
    "\n",
    "# last image\n",
    "startdate = os.path.splitext(os.path.basename(file_list[-1]))[0].split('_')[-2]\n",
    "enddate = os.path.splitext(os.path.basename(file_list[-1]))[0].split('_')[-1]\n",
    "\n",
    "stardate_lastproduct = datetime.datetime.strptime(startdate, \"%Y%j\")\n",
    "enddate_lastproduct = datetime.datetime.strptime(enddate, \"%Y%j\")\n",
    "\n",
    "# chech if it is a doy\n",
    "itsADoy = False\n",
    "if 'SeasonNdvi' in os.path.basename(file_list[0]):\n",
    "    itsADoy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if startdate_firstproduct.year == enddate_firstproduct.year and stardate_lastproduct.year == enddate_lastproduct.year:\n",
    "    \n",
    "    lta, projection, geotransform, no_data_value, data_type = calc_lta(file_list)\n",
    "    \n",
    "else:\n",
    "    if itsADoy:\n",
    "        lta, projection, geotransform, no_data_value, data_type = calc_lta_circ(file_list, True)\n",
    "    else:\n",
    "        lta, projection, geotransform, no_data_value, data_type = calc_lta(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(lta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_list)\n",
    "\n",
    "#print(startdate_firstproduct.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')\n",
    "\n",
    "\n",
    "#LE07_difNdvi_P001_2015005_2015020.tif\n",
    "region = filename[2]\n",
    "\n",
    "mission_name = filename[0]\n",
    "\n",
    "prod_type = filename[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if lta is not None:\n",
    "    #pdb.set_trace()\n",
    "    filename = write_output(output_folder, lta, startdate_firstproduct, enddate_lastproduct, mission_name, prod_type, region, projection, geotransform, 'GTiff', no_data_value, data_type)\n",
    "    \n",
    "    write_properties_file(filename, startdate_firstproduct, enddate_lastproduct, regionOfInterest['value'])\n",
    "\n",
    "    \n",
    "#lta[310,210]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vacc-env2",
   "language": "python",
   "name": "vacc-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
